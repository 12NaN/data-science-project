# Initial Findings

### (i) A 200-300 word explanation of the expected performance of the model in terms of mean squared error and the key features driving the team’s modeling performance. 

For the assignment, we tried three methods, Linear Regression, Random Forest Regressor, and the Decision Tree Regressor. But we found out that the Linear Regression is the most convenient one to use as it gave us the smaller mean squared error. We tried to use different features and a different number of features. We tried using three features which were {‘bedrooms', 'year_built', 'bathrooms'} and replacing empty values with the mean of the entire column (year_build), the mean squared error using Linear Regression, which gave us a mean squared error of 3098061.112076225 Then, we tried using four features which were {'bedrooms', 'year_built', 'bathrooms', 'min_to_subway'} but without replacing the empty values with the mean of the entire columns(year_build and min_to_subway), which gave us a mean squared error of 3098524.2259505177 using Linear Regression. Then after that, we once again used four features which were {'bedrooms', 'year_built', 'bathrooms', 'min_to_subway'} but this time replacing the empty values with the mean of the entire columns(year_build and min_to_subway), which gave us a mean squared error of  3155241.3377373447.
But we chose 3155241.3377373447 to be our mean squared error instead of the 3098524.2259505177 because this mean squared error is not replacing any empty values which are not giving accurate predictions for the rent, even though they have the same features. And we didn’t choose 3098061.112076225 because it has only 3 features and the difference between it and the one we chose is not big in terms of the mean squared error. We chose the features based on their high correlation with rent. 

### (ii) A 200-300 word summary outlining the team’s intended strategy to improve the predictions for the final round.

For the first part of the assignment, our strategy was to use features that had a high correlation with rent. With more features, we can probably get a better approximation as long as we can find a correlation with rent. Though we used three to four features to get a smaller MSE, some of the other features, such as borough and neighborhood, may become useful once we include outside data. Some features that can help our approximation are nearby schools, parks, crime rates and other factors that could be added later. For this project, we have mainly focused on using linear regression (for test2), and currently, we have a MSE of 3155241.3377373447 for test2 and a MSE of 2608675.2630168954 for test3. This score is definitely sufficient for the scope of this project, but we will attempt at getting a better score. The team has tried Linear Regression, Random Forest Regressor, and the Decision Tree Regressor for our training models, but our best result has come from linear regression (this only applied to the training set running against in the first submission). So, like everything in data science, we’ll try different training models with this final submission using these new features to get the best possible MSE (while still getting data that makes sense).
